<!DOCTYPE html>
<html lang="en">

<head>
    <title></title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<style>
    * {
        box-sizing: border-box;
        padding: 0;
        margin: 0;
    }

    img {
        width: 400px;
    }

    span {
        position: relative;
        display: inline-block;
    }

    #canvas {
        margin: auto;
        display: block;
    }

    .filter {
        margin: 50px auto;
        text-align: center;
    }

    .filter input {
        display: inline-block;
        margin: 0 20px;
    }
</style>

<body>


    <span><img id="image" style='display:none'/></span>
    <video id="video" width="800" height="530" loop src='../../source/jump.mp4' style='display:none'>
        <!--<source src="../../source/jump.mp4" type="video/mp4">
        <source src="../../source/jump.ogv" type="video/ogg">-->
    </video>
    <canvas id='canvas' width=500 height=500></canvas>
    <div class="filter">
        <input type="radio" name='filter' value=''>无
        <input type="radio" name='filter' value='invert'>反向
        <input type="radio" name='filter' value='grayscale'>灰化
        <input type="radio" name='filter' value='sepia'>复古
        <input type="radio" name='filter' value='brightness'>变量
        <input type="radio" name='filter' value='threshold'>阀值
        <input type="radio" name='filter' value='relief'>浮雕
        <input type="radio" name='filter' value='blur'>模糊
    </div>
    <script>
        window.onload = function () {
            if (!window.FaceDetector) {
                alert('该浏览器不支持人脸识别，Chrome 56+')
                return;
            }
            const image = document.querySelector("#image")
            const video = document.querySelector("#video")
            const canvas = document.querySelector("#canvas")
            const ctx = canvas.getContext('2d');
            const faceDetector = new FaceDetector({
                // 速度优先
                fastMode: false,
                // 最大识别
                maxDetectedFaces: 5
            });
            const canvasFilter = {
                invert(obj, i) {
                    obj[i] = 255 - obj[i];
                    obj[i + 1] = 255 - obj[i + 1];
                    obj[i + 2] = 255 - obj[i + 2];
                },
                grayscale(obj, i) {
                    var average = (obj[i] + obj[i + 1] + obj[i + 2]) / 3;
                    //var average = 0.2126*obj[i] + 0.7152*obj[i+1] + 0.0722*obj[i+2]; 或者
                    obj[i] = obj[i + 1] = obj[i + 2] = average;
                },
                sepia(obj, i) {
                    var r = obj[i],
                        g = obj[i + 1],
                        b = obj[i + 2];
                    obj[i] = (r * 0.393) + (g * 0.769) + (b * 0.189);
                    obj[i + 1] = (r * 0.349) + (g * 0.686) + (b * 0.168);
                    obj[i + 2] = (r * 0.272) + (g * 0.534) + (b * 0.131);
                },
                brightness(obj, i) {
                    var r = obj[i],
                        g = obj[i + 1],
                        b = obj[i + 2];
                    obj[i] += 30;
                    obj[i + 1] += 30;
                    obj[i + 2] += 30;
                },
                threshold(obj, i) {
                    var average = (obj[i] + obj[i + 1] + obj[i + 2]) / 3;
                    obj[i] = obj[i + 1] = obj[i + 2] = average > 150 ? 255 : 0;
                },
                relief(obj, i) {
                    if ((i + 1) % 4 !== 0) { // 每个像素点的第四个（0,1,2,3  4,5,6,7）是透明度。这里取消对透明度的处理
                        if ((i + 4) % (canvas.width * 4) == 0) { // 每行最后一个点，特殊处理。因为它后面没有边界点，所以变通下，取它前一个点
                            obj[i] = obj[i - 4];
                            obj[i + 1] = obj[i - 3];
                            obj[i + 2] = obj[i - 2];
                            obj[i + 3] = obj[i - 1];
                            i += 4;
                        } else {
                            // 取下一个点和下一行的同列点
                            obj[i] = 255 / 2 // 平均值
                                +
                                2 * obj[i] // 当前像素点
                                -
                                obj[i + 4] // 下一点
                                -
                                obj[i + canvas.width * 4]; // 下一行的同列点
                        }
                    } else { // 最后一行，特殊处理
                        if ((i + 1) % 4 !== 0) {
                            obj[i] = obj[i - canvas.width * 4];
                        }
                    }
                },
                blur(obj, i) {
                    obj[i + 3] -= 200;
                }
            };
            // 带上眼镜非常不准
            function draw() {
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                ctx.stroke();
                var filter = [...document.getElementsByName("filter")].filter(item => {
                    return item.checked;
                })
                if (filter.length && filter[0].value) {
                    const imgData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                    for (var i = 0, len = imgData.data.length; i < len; i += 4) {
                        canvasFilter[filter[0].value](imgData.data, i);
                    }
                    ctx.putImageData(imgData, 0, 0);
                }


                image.src = canvas.toDataURL('images/png');
                image.onload = () => {
                    scale = canvas.width / image.width;
                    faceDetector.detect(image)
                        .then(faces => {
                            ctx.beginPath();
                            ctx.lineWidth = 2;
                            ctx.strokeStyle = 'red';
                            for (let face of faces) {
                                const x = Math.floor(face.boundingBox.x * scale)
                                const y = Math.floor(face.boundingBox.y * scale)
                                const w = Math.floor(face.boundingBox.width * scale);
                                const h = Math.floor(face.boundingBox.height * scale);
                                // const imgData = ctx.getImageData(x, y, w, h);
                                // for (var i = 0, len = imgData.data.length; i < len; i += 4) {
                                //     canvasFilter.invert(imgData.data, i);
                                // }
                                // ctx.putImageData(imgData, x, y);

                                ctx.rect(x, y, w, h);
                            }
                            // ctx.stroke();
                        })
                    requestAnimationFrame(draw)
                }

            }
            video.play();
            draw()
        }
    </script>
</body>

</html>